{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOU Tracker\n",
    "\n",
    "IOUTracker implements a tracking algorithm or method to track objects based on their Intersection-Over-Union (IOU) information across the consecutive frames. The core concept of this algorithm refers to the article (http://elvera.nue.tu-berlin.de/files/1517Bochinski2017.pdf). The idea or the assumption is based on an existing and powerful detector and the high frame rate across the consecutive frames. Under this assumption, you can conduct the object tracking with only the localization and the IOU information. The algorithm conducts under a super-high frame rate and provides a foundation for more complicated calculations upon it. \n",
    "\n",
    "On the other hand, such an algorithm requires an evaluation. The evaluation of this implement also refers to two articles, MOT16 benchmark (https://arxiv.org/abs/1603.00831) and Multi-Target Tracker (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.309.8335&rep=rep1&type=pdf).\n",
    "\n",
    "This implementation uses MOT17Det dataset (https://motchallenge.net/data/MOT17Det/) as an example.\n",
    "\n",
    "* More information please refer to https://github.com/jiankaiwang/ioutracker.\n",
    "* More example videos please refer to ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Load ioutracker from the relative path.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "try:\n",
    "  # you must install ioutracker first\n",
    "  from ioutracker import loadLabel, outputAsFramesToVideo, IOUTracker\n",
    "  from ioutracker import EvaluateOnMOTDatasets, ExampleEvaluateMOTDatasets\n",
    "  logging.warning(\"Load ioutracker from the installed package.\")\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  modulePaths = [os.path.join(\"..\")]\n",
    "  for path in modulePaths: sys.path.append(path)\n",
    "  from ioutracker.dataloaders.MOTDataLoader import loadLabel\n",
    "  from ioutracker.inference.MOTDet17Main import outputAsFramesToVideo\n",
    "  from ioutracker.inference.MOTDet17Main import outputAsFramesToVideo\n",
    "  from ioutracker.src.IOUTracker import IOUTracker\n",
    "  from ioutracker.metrics.MOTMetrics import EvaluateOnMOTDatasets, ExampleEvaluateMOTDatasets\n",
    "  logging.warning(\"Load ioutracker from the relative path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "You can use the shell script under the path, (`./ioutracker/dataloaders/MOTDataDownloader.sh`), in the git repository to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_DATASET = \"train\"\n",
    "VERSION = \"MOT17Det\"\n",
    "LOCAL_PATH = os.path.join(\"/\", \"tmp\", \"MOT\")\n",
    "\n",
    "# you can change the path pointing to the dataset\n",
    "LABEL_PATH = os.path.join(LOCAL_PATH, \"{}\".format(VERSION + \"Labels\"), SUB_DATASET)\n",
    "assert os.path.exists(LABEL_PATH), \"{} is not found.\".format(LABEL_PATH)\n",
    "\n",
    "# you can change the path pointing to the dataset\n",
    "FRAME_PATH = os.path.join(LOCAL_PATH, \"{}\".format(VERSION), SUB_DATASET)\n",
    "assert os.path.exists(FRAME_PATH), \"{} is not found.\".format(FRAME_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOT17-02', 'MOT17-04', 'MOT17-05', 'MOT17-09', 'MOT17-10', 'MOT17-11', 'MOT17-13']\n"
     ]
    }
   ],
   "source": [
    "totalSamples = next(os.walk(os.path.join(LABEL_PATH)))[1]\n",
    "print(totalSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"MOT17-10\"\n",
    "LABEL_FILE_PATH = os.path.join(LABEL_PATH, SAMPLE, \"gt\", \"gt.txt\")\n",
    "assert os.path.exists(LABEL_FILE_PATH), \"{} is not found.\".format(LABEL_FILE_PATH)\n",
    "\n",
    "FRAME_FILE_PATH = os.path.join(FRAME_PATH, SAMPLE, \"img1\")\n",
    "assert os.path.exists(FRAME_FILE_PATH), \"{} is not found.\".format(FRAME_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the tracking result on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample MOT17-10 with FPS: 30\n"
     ]
    }
   ],
   "source": [
    "FRAME_FPS = {\"MOT17-13\": 25, \"MOT17-11\": 30, \"MOT17-10\": 30, \"MOT17-09\": 30,\n",
    "             \"MOT17-05\": 14, \"MOT17-04\": 30, \"MOT17-02\": 30}\n",
    "assert SAMPLE in list(FRAME_FPS.keys()), \"{} was not found.\".format(SAMPLE)\n",
    "fps = FRAME_FPS[SAMPLE]\n",
    "print(\"Sample {} with FPS: {}\".format(SAMPLE, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether or not the folder is existing, or create it if it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_output = os.path.join(LOCAL_PATH, \"tracking_output\".format(VERSION))\n",
    "if not os.path.exists(tracking_output):\n",
    "  try:\n",
    "    os.mkdir(tracking_output)\n",
    "    print(\"Created the output path: {}\".format(tracking_output))\n",
    "  except Exception as e:\n",
    "    raise Exception(\"Can't create the folder. ({})\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we introduce how to output the tracking result on the consecutive frame to a video file. Notice the flag `plotting` must be set to `True` if you want to output the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [01:05<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time cost: 144.47552704811096\n"
     ]
    }
   ],
   "source": [
    "outputAsFramesToVideo(detection_conf=0.2,\n",
    "                      iou_threshold=0.2,\n",
    "                      min_t=fps,\n",
    "                      track_min_conf=0.5,\n",
    "                      labelFilePath=LABEL_FILE_PATH,\n",
    "                      frameFilePath=FRAME_FILE_PATH,\n",
    "                      trackingOutput=tracking_output,\n",
    "                      fps=fps,\n",
    "                      outputFileName=SAMPLE,\n",
    "                      plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can move the video to the desired path like below.\n",
    "\n",
    "```sh\n",
    "mv /tmp/MOT/tracking_output/tracking_MOT17-04.mp4 ~/Desktop/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MOT data first via the API `loadLabel`. You can also use `help` to take a look into the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS, DFPERSONS = loadLabel(src=LABEL_FILE_PATH, format_style=\"metrics_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function loadLabel in module ioutracker.dataloaders.MOTDataLoader:\n",
      "\n",
      "loadLabel(src, is_path=True, load_Pedestrian=True, load_Static_Person=True, visible_thresholde=0, format_style='onlybbox')\n",
      "    LoadLabel: Load a label file in the csv format.\n",
      "    \n",
      "    Args:\n",
      "      src: the MOT label file path (available when is_path is True)\n",
      "      is_path: True or False for whether the src is the file path or not\n",
      "      load_Pedestrian: whether to load the pedestrian data or not\n",
      "      load_Static_Person: whether to load the statuc person data or not\n",
      "      visible_thresholde: the threshold for filtering the invisible person data\n",
      "      format_style: provides different styles in the lists,\n",
      "                    \"onlybbox\" (func: formatBBoxAndVis), \"onlybbox_dict\" (func: formatBBoxAndVis),\n",
      "                    \"metrics\" (func: formatForMetrics), \"metrics_dict\" (func: formatForMetrics)\n",
      "    \n",
      "    Returns:\n",
      "      objects_in_frames: a list contains the person detection information per frames\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loadLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABELS is a dictionary whose key is the frame ID and whose value is each object detection result. The result keeps the localization and visibility in a list, more detail is `[x, y, w, h, visibility]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " [[1368.0, 394.0, 74.0, 226.0, 1.0, 1.0],\n",
       "  [1478.0, 418.0, 74.0, 176.0, 1.0, 2.0],\n",
       "  [680.0, 407.0, 67.0, 199.0, 1.0, 3.0],\n",
       "  [1232.0, 412.0, 36.0, 112.0, 1.0, 4.0],\n",
       "  [470.0, 432.0, 72.0, 176.0, 1.0, 5.0],\n",
       "  [730.0, 421.0, 55.0, 173.0, 0.67857, 6.0],\n",
       "  [550.0, 436.0, 60.0, 170.0, 1.0, 8.0],\n",
       "  [960.0, 416.0, 39.0, 110.0, 0.82342, 12.0],\n",
       "  [1170.0, 418.0, 38.0, 104.0, 1.0, 13.0],\n",
       "  [590.0, 427.0, 55.0, 177.0, 0.6439600000000001, 15.0],\n",
       "  [1112.0, 418.0, 32.0, 81.0, 1.0, 18.0],\n",
       "  [398.0, 435.0, 28.0, 69.0, 0.62857, 22.0],\n",
       "  [635.0, 426.0, 52.0, 137.0, 0.6430100000000001, 23.0],\n",
       "  [1196.0, 418.0, 28.0, 94.0, 0.55172, 26.0],\n",
       "  [843.0, 426.0, 20.0, 67.0, 0.7395, 27.0],\n",
       "  [825.0, 433.0, 21.0, 57.0, 0.63636, 28.0],\n",
       "  [858.0, 432.0, 21.0, 71.0, 1.0, 38.0],\n",
       "  [809.0, 429.0, 19.0, 61.0, 0.8129, 39.0],\n",
       "  [780.0, 427.0, 21.0, 67.0, 0.72727, 40.0],\n",
       "  [1594.0, 423.0, 41.0, 107.0, 1.0, 61.0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELS[1]), LABELS[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFPERSONS is a pandas dataframe object that is processed and filtered unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>uid</th>\n",
       "      <th>bX</th>\n",
       "      <th>bY</th>\n",
       "      <th>bW</th>\n",
       "      <th>bH</th>\n",
       "      <th>conf</th>\n",
       "      <th>class</th>\n",
       "      <th>visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1368</td>\n",
       "      <td>394</td>\n",
       "      <td>74</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "      <td>394</td>\n",
       "      <td>75</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1365</td>\n",
       "      <td>394</td>\n",
       "      <td>76</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1363</td>\n",
       "      <td>394</td>\n",
       "      <td>77</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1362</td>\n",
       "      <td>394</td>\n",
       "      <td>78</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fid  uid    bX   bY  bW   bH  conf  class  visible\n",
       "0    1    1  1368  394  74  226     1      1      1.0\n",
       "1    2    1  1366  394  75  229     1      1      1.0\n",
       "2    3    1  1365  394  76  232     1      1      1.0\n",
       "3    4    1  1363  394  77  235     1      1      1.0\n",
       "4    5    1  1362  394  78  238     1      1      1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFPERSONS.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can instantiate an IOUTracker to start the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IOUTracker in module ioutracker.src.IOUTracker:\n",
      "\n",
      "class IOUTracker(builtins.object)\n",
      " |  IOUTracker(detection_conf=0.2, iou_threshold=0.5, min_t=1, track_min_conf=0.2, assignedTID=True)\n",
      " |  \n",
      " |  IOUTracker implements the IOU tracker algorithm details.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, detections, returnFinishedTrackers=False)\n",
      " |      Runs the IOU tracker algorithm across the consecutive frames.\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: a list contains multiple detections per frame, each detection\n",
      " |                    keeps [[bX, bY, bWidth, bHeight, visible], [], []]\n",
      " |      \n",
      " |        returnFinishedTrackers: a bool for returning finished trackers\n",
      " |      \n",
      " |      Returns:\n",
      " |        detectionMapping: a list contains multiple dictionary-structure objects\n",
      " |                          representing each detection, the order of those objects\n",
      " |                          is the same to the detection, the prototype is like\n",
      " |      \n",
      " |                          [{\"tid\": value, \"numFrames\": value, \"largerThanMinT\": Bool}]\n",
      " |      \n",
      " |                          in which numFrames is the number of objects in the history\n",
      " |                          , and largerThanMinT is a bool value for the numFrames larger\n",
      " |                          than min_t, if tid == -1, it represents this detection is\n",
      " |                          unassigned\n",
      " |        finishedTrackers: (optional)\n",
      " |                          a list contains multiple dictionary-structure objects\n",
      " |                          representing each finished tracks, the prototype is like\n",
      " |      \n",
      " |                          [{\"ftid\": value, \"numFrames\": value, \"largerThanMinT\": Bool}]\n",
      " |      \n",
      " |                          in which the finishedTracking is similiar to the activeTracking\n",
      " |                          , the difference are that in finishedTracking ftid is\n",
      " |                          finished tid and finishedTrackers keeps all finished\n",
      " |                          trackers from the beginning\n",
      " |  \n",
      " |  __del__(self)\n",
      " |      Delete this object.\n",
      " |  \n",
      " |  __init__(self, detection_conf=0.2, iou_threshold=0.5, min_t=1, track_min_conf=0.2, assignedTID=True)\n",
      " |      Constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        detection_conf (sigma_l): the detection was removed when its confident score\n",
      " |                                  is lower than detection_conf\n",
      " |        iou_threshold (sigma_IOU): the min IOU threshold between a detection and\n",
      " |                                   active tracks\n",
      " |        min_t: the track is filtered out when its length is shorter than min_t\n",
      " |        track_min_conf (sigma_h): the track is filtered out when all of its detections'\n",
      " |                                  confident scores are less than the track_min_conf\n",
      " |        assignedTID: the flag to automatically assign a tracker ID to a track,\n",
      " |                     if it is set to False, you can assign a customized TID later\n",
      " |  \n",
      " |  clear_finished_tracks(self)\n",
      " |      clear_finished_tracks cleans finished tracks.\n",
      " |  \n",
      " |  get_active_tracks(self)\n",
      " |      get_active_tracks gets the current active tracks.\n",
      " |      \n",
      " |      Args: None\n",
      " |      \n",
      " |      Returns:\n",
      " |        active_tracks: a list of active tracks that each is a Track object\n",
      " |  \n",
      " |  get_finished_tracks(self)\n",
      " |      get_finished_tracks gets the finished tracks.\n",
      " |      \n",
      " |      Args: None\n",
      " |      \n",
      " |      Returns:\n",
      " |        finished_tracks: a list of finished tracks that each is a Track object\n",
      " |  \n",
      " |  read_detections_per_frame(self, detections)\n",
      " |      read_detections_per_frame: start to parse the detections per frame.\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: a list contains multiple detections per frame, each detection\n",
      " |                    keeps [[bX, bY, bWidth, bHeight, visible], [], []]\n",
      " |      \n",
      " |      Returns: None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  filter_detections(detections, detection_threshold)\n",
      " |      Filter the detections whose scores are lower than the IOU threshold.\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: a list of multiple detections per frame\n",
      " |        detection_threshold: the minimum confident score\n",
      " |      \n",
      " |      Returns:\n",
      " |        available_detections: a list that removes the detections whose visible\n",
      " |                              (or probability) is lower than the detection_conf\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  detection_conf\n",
      " |      detection_conf.getter\n",
      " |  \n",
      " |  iou_threshold\n",
      " |      iou_threshold.getter\n",
      " |  \n",
      " |  min_t\n",
      " |      min_t.getter\n",
      " |  \n",
      " |  track_min_conf\n",
      " |      track_min_conf.getter\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  active_tracks = []\n",
      " |  \n",
      " |  finished_tracks = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(IOUTracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ioutracker that implements the IOU tracker algorithm. In this example, we use the default ID increment mechanism to get the tracker ID for each box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............Frame: 150\n",
      "BBox: [999.0, 357.0, 67.0, 167.0, 1.0, 2.0], and its Track ID: 24\n",
      "BBox: [899.0, 353.0, 45.0, 127.0, 1.0, 4.0], and its Track ID: 4\n",
      "BBox: [805.0, 345.0, 40.0, 124.0, 1.0, 7.0], and its Track ID: 51\n",
      "BBox: [1796.0, 320.0, 194.0, 589.0, 0.64103, 9.0], and its Track ID: 1\n",
      "BBox: [60.0, 351.0, 107.0, 243.0, 1.0, 11.0], and its Track ID: 71\n",
      "BBox: [592.0, 354.0, 59.0, 141.0, 0.5493, 12.0], and its Track ID: 59\n",
      "BBox: [890.0, 357.0, 40.0, 119.0, 0.21950999999999998, 13.0], and its Track ID: 82\n",
      "BBox: [-12.0, 392.0, 73.0, 195.0, 0.7973, 16.0], and its Track ID: 79\n",
      "BBox: [922.0, 354.0, 38.0, 104.0, 0.41026, 18.0], and its Track ID: 81\n",
      "BBox: [336.0, 372.0, 49.0, 131.0, 1.0, 23.0], and its Track ID: 70\n",
      "BBox: [1100.0, 336.0, 62.0, 169.0, 1.0, 24.0], and its Track ID: 72\n",
      "BBox: [999.0, 353.0, 30.0, 115.0, 0.034483, 26.0], and its Track ID: -1\n",
      "BBox: [535.0, 368.0, 31.0, 103.0, 0.98798, 29.0], and its Track ID: 75\n",
      "BBox: [513.0, 376.0, 28.0, 87.0, 0.75862, 30.0], and its Track ID: 64\n",
      "BBox: [585.0, 367.0, 34.0, 102.0, 0.12621, 34.0], and its Track ID: -1\n",
      "BBox: [537.0, 378.0, 30.0, 58.0, 0.029524, 41.0], and its Track ID: -1\n",
      "BBox: [831.0, 366.0, 25.0, 69.0, 0.42308, 43.0], and its Track ID: 74\n",
      "BBox: [187.0, 375.0, 21.0, 67.0, 1.0, 44.0], and its Track ID: 77\n",
      "BBox: [232.0, 379.0, 33.0, 102.0, 1.0, 45.0], and its Track ID: 76\n",
      "BBox: [732.0, 384.0, 35.0, 51.0, 1.0, 51.0], and its Track ID: 62\n",
      "BBox: [754.0, 386.0, 30.0, 48.0, 0.5483899999999999, 52.0], and its Track ID: 67\n",
      "BBox: [235.0, 374.0, 23.0, 64.0, 0.076923, 54.0], and its Track ID: -1\n",
      "BBox: [1543.0, 357.0, 56.0, 143.0, 1.0, 61.0], and its Track ID: 58\n",
      "BBox: [562.0, 382.0, 25.0, 53.0, 0.60541, 71.0], and its Track ID: 80\n",
      "...\n",
      "...............Frame: 300\n",
      "BBox: [1111.0, 266.0, 61.0, 151.0, 1.0, 2.0], and its Track ID: 24\n",
      "BBox: [883.0, 259.0, 49.0, 149.0, 0.38, 4.0], and its Track ID: 136\n",
      "BBox: [841.0, 249.0, 72.0, 195.0, 1.0, 7.0], and its Track ID: 4\n",
      "BBox: [1478.0, 194.0, 246.0, 749.0, 0.89474, 9.0], and its Track ID: 1\n",
      "BBox: [1699.0, 168.0, 282.0, 814.0, 0.78445, 10.0], and its Track ID: 91\n",
      "BBox: [509.0, 243.0, 73.0, 227.0, 0.52632, 12.0], and its Track ID: 59\n",
      "BBox: [927.0, 266.0, 55.0, 131.0, 0.89286, 13.0], and its Track ID: 81\n",
      "BBox: [994.0, 274.0, 23.0, 50.0, 1.0, 14.0], and its Track ID: 120\n",
      "BBox: [1044.0, 255.0, 48.0, 139.0, 0.23499, 18.0], and its Track ID: 117\n",
      "BBox: [525.0, 277.0, 48.0, 114.0, 0.0, 23.0], and its Track ID: -1\n",
      "BBox: [1049.0, 267.0, 40.0, 131.0, 1.0, 25.0], and its Track ID: 133\n",
      "BBox: [1176.0, 261.0, 34.0, 118.0, 1.0, 26.0], and its Track ID: 96\n",
      "BBox: [335.0, 249.0, 73.0, 195.0, 0.78709, 29.0], and its Track ID: 75\n",
      "BBox: [297.0, 273.0, 54.0, 174.0, 1.0, 30.0], and its Track ID: 64\n",
      "BBox: [784.0, 275.0, 45.0, 109.0, 0.43478, 31.0], and its Track ID: 134\n",
      "BBox: [763.0, 274.0, 46.0, 113.0, 1.0, 32.0], and its Track ID: 62\n",
      "BBox: [609.0, 273.0, 44.0, 131.0, 0.47726999999999997, 34.0], and its Track ID: 135\n",
      "BBox: [101.0, 267.0, 37.0, 93.0, 0.97564, 44.0], and its Track ID: 130\n",
      "BBox: [141.0, 271.0, 50.0, 133.0, 1.0, 45.0], and its Track ID: 76\n",
      "BBox: [853.0, 292.0, 38.0, 53.0, 0.0, 51.0], and its Track ID: -1\n",
      "BBox: [885.0, 290.0, 33.0, 53.0, 0.0, 52.0], and its Track ID: -1\n",
      "BBox: [162.0, 277.0, 33.0, 77.0, 0.08295599999999999, 54.0], and its Track ID: -1\n",
      "BBox: [758.0, 271.0, 21.0, 64.0, 0.26294, 56.0], and its Track ID: 103\n",
      "BBox: [733.0, 273.0, 20.0, 70.0, 0.8169, 57.0], and its Track ID: 112\n",
      "BBox: [663.0, 279.0, 22.0, 58.0, 0.58659, 59.0], and its Track ID: 128\n",
      "BBox: [678.0, 281.0, 26.0, 56.0, 0.61728, 71.0], and its Track ID: 121\n",
      "...\n",
      "...............Frame: 450\n",
      "BBox: [1146.0, 324.0, 59.0, 149.0, 0.53333, 2.0], and its Track ID: 183\n",
      "BBox: [808.0, 317.0, 58.0, 162.0, 1.0, 4.0], and its Track ID: 136\n",
      "BBox: [324.0, 250.0, 213.0, 442.0, 1.0, 12.0], and its Track ID: 169\n",
      "BBox: [911.0, 328.0, 54.0, 152.0, 1.0, 13.0], and its Track ID: 81\n",
      "BBox: [1066.0, 334.0, 33.0, 71.0, 1.0, 14.0], and its Track ID: 120\n",
      "BBox: [1196.0, 291.0, 55.0, 242.0, 1.0, 18.0], and its Track ID: 24\n",
      "BBox: [598.0, 334.0, 40.0, 102.0, 0.81553, 23.0], and its Track ID: 157\n",
      "BBox: [1178.0, 310.0, 59.0, 212.0, 0.3, 25.0], and its Track ID: 182\n",
      "BBox: [91.0, 338.0, 71.0, 152.0, 0.9332799999999999, 31.0], and its Track ID: 178\n",
      "BBox: [966.0, 337.0, 28.0, 63.0, 1.0, 33.0], and its Track ID: 170\n",
      "BBox: [448.0, 336.0, 45.0, 177.0, 0.0, 34.0], and its Track ID: -1\n",
      "BBox: [1003.0, 343.0, 21.0, 41.0, 1.0, 49.0], and its Track ID: 152\n",
      "BBox: [978.0, 338.0, 17.0, 48.0, 0.055555999999999994, 50.0], and its Track ID: -1\n",
      "BBox: [868.0, 356.0, 46.0, 70.0, 0.8381799999999999, 51.0], and its Track ID: 173\n",
      "BBox: [907.0, 363.0, 41.0, 69.0, 0.095238, 52.0], and its Track ID: -1\n",
      "BBox: [658.0, 339.0, 29.0, 72.0, 1.0, 56.0], and its Track ID: 155\n",
      "BBox: [593.0, 332.0, 36.0, 83.0, 0.15573, 57.0], and its Track ID: -1\n",
      "BBox: [673.0, 340.0, 24.0, 65.0, 0.018182, 59.0], and its Track ID: -1\n",
      "BBox: [684.0, 343.0, 22.0, 63.0, 0.82609, 71.0], and its Track ID: 181\n",
      "...\n",
      "...............Frame: 600\n",
      "BBox: [1139.0, 329.0, 55.0, 137.0, 1.0, 2.0], and its Track ID: 120\n",
      "BBox: [749.0, 312.0, 62.0, 176.0, 1.0, 4.0], and its Track ID: 136\n",
      "BBox: [831.0, 326.0, 56.0, 160.0, 1.0, 13.0], and its Track ID: 81\n",
      "BBox: [1265.0, 316.0, 75.0, 157.0, 1.0, 14.0], and its Track ID: 202\n",
      "BBox: [1756.0, 170.0, 209.0, 775.0, 0.78571, 18.0], and its Track ID: 24\n",
      "BBox: [741.0, 332.0, 44.0, 111.0, 0.17778, 23.0], and its Track ID: -1\n",
      "BBox: [1631.0, 218.0, 200.0, 622.0, 0.6218899999999999, 25.0], and its Track ID: 190\n",
      "BBox: [1034.0, 333.0, 32.0, 73.0, 1.0, 33.0], and its Track ID: 170\n",
      "BBox: [25.0, 327.0, 39.0, 109.0, 1.0, 47.0], and its Track ID: 210\n",
      "BBox: [66.0, 323.0, 50.0, 112.0, 1.0, 48.0], and its Track ID: 205\n",
      "BBox: [1107.0, 343.0, 24.0, 57.0, 1.0, 49.0], and its Track ID: 152\n",
      "BBox: [1079.0, 346.0, 24.0, 62.0, 1.0, 50.0], and its Track ID: 189\n",
      "BBox: [914.0, 352.0, 58.0, 109.0, 0.8339, 51.0], and its Track ID: 198\n",
      "BBox: [962.0, 364.0, 53.0, 98.0, 1.0, 52.0], and its Track ID: 193\n",
      "BBox: [610.0, 337.0, 25.0, 57.0, 1.0, 65.0], and its Track ID: 207\n",
      "BBox: [631.0, 342.0, 22.0, 50.0, 0.78261, 66.0], and its Track ID: 206\n",
      "BBox: [642.0, 334.0, 22.0, 46.0, 0.39315, 67.0], and its Track ID: 203\n",
      "BBox: [661.0, 330.0, 23.0, 50.0, 0.84641, 68.0], and its Track ID: 211\n",
      "BBox: [723.0, 348.0, 29.0, 58.0, 0.6, 69.0], and its Track ID: 212\n",
      "BBox: [677.0, 338.0, 20.0, 41.0, 0.42857, 72.0], and its Track ID: 200\n",
      "BBox: [694.0, 337.0, 22.0, 42.0, 0.8301299999999999, 73.0], and its Track ID: 208\n",
      "...\n",
      "....."
     ]
    }
   ],
   "source": [
    "iouTracks = IOUTracker(detection_conf=0.2,\n",
    "                       iou_threshold=0.2,\n",
    "                       min_t=fps,\n",
    "                       track_min_conf=0.5, \n",
    "                       assignedTID=True)\n",
    "\n",
    "for frameIdx in range(1, len(LABELS), 1):\n",
    "  if frameIdx % 10 == 0: print('.', end='')\n",
    "  \n",
    "  # iou tracker\n",
    "  detectionMapping, _ = iouTracks(LABELS[frameIdx])\n",
    "\n",
    "  if frameIdx % (fps * 5) == 0:\n",
    "    print(\"Frame: {}\".format(frameIdx))\n",
    "    for bboxIdx in range(len(LABELS[frameIdx])):\n",
    "      print(\"BBox: {}, and its Track ID: {}\".format(LABELS[frameIdx][bboxIdx], detectionMapping[bboxIdx][\"tid\"]))\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `tid_count` is used to assign the unique ID to each track. \n",
    "\n",
    "In this implementation, the IOUTracker is designed to take object detection results frame by frame, not a whole video. It keeps the information of each track. You can access the active tracks via the `get_active_tracks()` method, and watch the finished tracks via the `get_finished_tracks()` method.\n",
    " \n",
    "On the other hand, you can access the attribute `tid` of each track to get the relative track ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 50 tracker Info: active 19, finished 3\n",
      "Frame 100 tracker Info: active 15, finished 13\n",
      "Frame 150 tracker Info: active 20, finished 17\n",
      "Frame 200 tracker Info: active 21, finished 22\n",
      "Frame 250 tracker Info: active 20, finished 27\n",
      "Frame 300 tracker Info: active 22, finished 31\n",
      "Frame 350 tracker Info: active 16, finished 40\n",
      "Frame 400 tracker Info: active 17, finished 45\n",
      "Frame 450 tracker Info: active 14, finished 54\n",
      "Frame 500 tracker Info: active 16, finished 57\n",
      "Frame 550 tracker Info: active 20, finished 61\n",
      "Frame 600 tracker Info: active 20, finished 66\n",
      "Frame 650 tracker Info: active 15, finished 71\n"
     ]
    }
   ],
   "source": [
    "iouTracks = IOUTracker(detection_conf=0.2,\n",
    "                       iou_threshold=0.2,\n",
    "                       min_t=fps,\n",
    "                       track_min_conf=0.5, \n",
    "                       assignedTID=False)\n",
    "\n",
    "tid_count = 1\n",
    "\n",
    "for label in range(1, len(LABELS), 1):\n",
    "  # iou tracker\n",
    "  iouTracks.read_detections_per_frame(detections=LABELS[label])\n",
    "\n",
    "  active_tacks = iouTracks.get_active_tracks()\n",
    "  finished_tracks = iouTracks.get_finished_tracks()\n",
    "\n",
    "  if label % 50 == 0:\n",
    "    print(\"Frame {} tracker Info: active {}, finished {}\".format(label, len(active_tacks), len(finished_tracks)))\n",
    "  \n",
    "  # simple way to assign the tracker ID\n",
    "  for act_track in active_tacks:\n",
    "    if not act_track.tid:\n",
    "      # assign track id to use the color\n",
    "      act_track.tid = tid_count\n",
    "      tid_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExampleEvaluateMOTDatasets helps you evaluate on each dataset or each video. Here we use the same ground truth data as the predictions to test the functionality due to the lack of a detector.\n",
    "\n",
    "Notice that this step takes a long time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions, _ = loadLabel(src=LABEL_FILE_PATH, is_path=True, load_Pedestrian=True, load_Static_Person=True,\n",
    "    visible_thresholde=0.2, format_style=\"metrics_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [06:39<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 11703\n",
      "FP:     0\n",
      "FN:     0\n",
      "GT: 11703\n",
      "Fragment Number:    131\n",
      "SwitchID Number:    283\n",
      "Recall: 100.000%\n",
      "Precision: 100.000%\n",
      "Accuracy: 100.000%\n",
      "F1 Score: 1.000\n",
      "MOTA: 0.975818\n",
      "Total trajectories: 60\n",
      "MT Number: 60, Ratio: 100.000%\n",
      "PT Number: 0, Ratio: 0.000%\n",
      "ML Number: 0, Ratio: 0.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalMOT = ExampleEvaluateMOTDatasets(LABEL_FILE_PATH, predictions=Predictions, printOnScreen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvaluateOnMOTDatasets class helps you evaluate the multiple datastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric mota: Value 0.9758181662821499\n",
      "Metric recall: Value 1.0\n",
      "Metric precision: Value 1.0\n",
      "Metric accuracy: Value 1.0\n",
      "Metric f1score: Value 1.0\n",
      "Metric rateMT: Value 1.0\n",
      "Metric ratePT: Value 0.0\n",
      "Metric rateML: Value 0.0\n",
      "Metric TP: Value 23406\n",
      "Metric FP: Value 0\n",
      "Metric FN: Value 0\n",
      "Metric GT: Value 23406\n",
      "Metric numFragments: Value 131\n",
      "Metric numSwitchID: Value 283\n",
      "Metric numMT: Value 60\n",
      "Metric numPT: Value 0\n",
      "Metric numML: Value 0\n",
      "Metric numTraj: Value 60\n"
     ]
    }
   ],
   "source": [
    "evalMOTData = EvaluateOnMOTDatasets()\n",
    "\n",
    "# it is simple to pass the whole package of results into the multiple-dataset evaluator\n",
    "evalMOTData(evalMOT)\n",
    "evalMOTRes = evalMOTData.getResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also evaluate metrics on each MOT datasets and then summarize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMOTData = EvaluateOnMOTDatasets()\n",
    "for key, _ in FRAME_FPS.items():\n",
    "  LABEL_FILE_PATH = os.path.join(LABEL_PATH, key, \"gt\", \"gt.txt\")\n",
    "  assert os.path.exists(LABEL_FILE_PATH), \"{} is not found.\".format(LABEL_FILE_PATH)\n",
    "  print(\"Sample: {}\".format(key))\n",
    "  \n",
    "  # here predictions flag is set to None, it makes to use the ground truth as the prediction\n",
    "  evalMOT = ExampleEvaluateMOTDatasets(LABEL_FILE_PATH, predictions=None, printOnScreen=True)\n",
    "  evalMOTData(evalMOT)\n",
    "  print(\"\", end=\"\\n\\n\")\n",
    "evalMOTRes = evalMOTData.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
