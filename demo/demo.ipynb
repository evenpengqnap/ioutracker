{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOU Tracker\n",
    "\n",
    "IOUTracker implements a tracking algorithm or method to track objects based on their Intersection-Over-Union (IOU) information across the consecutive frames. The core concept of this algorithm refers to the article (http://elvera.nue.tu-berlin.de/files/1517Bochinski2017.pdf). The idea or the assumption is based on an existing and powerful detector and the high frame rate across the consecutive frames. Under this assumption, you can conduct the object tracking with only the localization and the IOU information. The algorithm conducts under a super-high frame rate and provides a foundation for more complicated calculations upon it. \n",
    "\n",
    "On the other hand, such an algorithm requires an evaluation. The evaluation of this implement also refers to two articles, MOT16 benchmark (https://arxiv.org/abs/1603.00831) and Multi-Target Tracker (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.309.8335&rep=rep1&type=pdf).\n",
    "\n",
    "This implementation uses MOT17Det dataset (https://motchallenge.net/data/MOT17Det/) as an example.\n",
    "\n",
    "* More information please refer to https://github.com/jiankaiwang/ioutracker.\n",
    "* More example videos please refer to ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  # you must install ioutracker first\n",
    "  from ioutracker import loadLabel, outputAsFramesToVideo, IOUTracker\n",
    "  from ioutracker import EvaluateOnMOTDatasets, ExampleEvaluateMOTDatasets\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  modulePaths = [os.path.join(\".\", \"ioutracker\")]\n",
    "  for path in modulePaths: sys.path.append(path)\n",
    "  from ioutracker.dataloaders.MOTDataLoader import loadLabel\n",
    "  from ioutracker.inference.MOTDet17Main import outputAsFramesToVideo\n",
    "  from ioutracker.inference.MOTDet17Main import outputAsFramesToVideo\n",
    "  from ioutracker.src.IOUTracker import IOUTracker\n",
    "  from ioutracker.metrics.MOTMetrics import EvaluateOnMOTDatasets, ExampleEvaluateMOTDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "You can use the shell script under the path, (`./ioutracker/dataloaders/MOTDataDownloader.sh`), in the git repository to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_DATASET = \"train\"\n",
    "VERSION = \"MOT17Det\"\n",
    "LOCAL_PATH = os.path.join(\"/\", \"tmp\", \"MOT\")\n",
    "\n",
    "# you can change the path pointing to the dataset\n",
    "LABEL_PATH = os.path.join(LOCAL_PATH, \"{}\".format(VERSION + \"Labels\"), SUB_DATASET)\n",
    "assert os.path.exists(LABEL_PATH), \"{} is not found.\".format(LABEL_PATH)\n",
    "\n",
    "# you can change the path pointing to the dataset\n",
    "FRAME_PATH = os.path.join(LOCAL_PATH, \"{}\".format(VERSION), SUB_DATASET)\n",
    "assert os.path.exists(FRAME_PATH), \"{} is not found.\".format(FRAME_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MOT17-13', 'MOT17-09', 'MOT17-11', 'MOT17-10', 'MOT17-04', 'MOT17-05', 'MOT17-02']\n"
     ]
    }
   ],
   "source": [
    "totalSamples = next(os.walk(os.path.join(LABEL_PATH)))[1]\n",
    "print(totalSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"MOT17-02\"\n",
    "LABEL_FILE_PATH = os.path.join(LABEL_PATH, SAMPLE, \"gt\", \"gt.txt\")\n",
    "assert os.path.exists(LABEL_FILE_PATH), \"{} is not found.\".format(LABEL_FILE_PATH)\n",
    "\n",
    "FRAME_FILE_PATH = os.path.join(FRAME_PATH, SAMPLE, \"img1\")\n",
    "assert os.path.exists(FRAME_FILE_PATH), \"{} is not found.\".format(FRAME_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the tracking result on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample MOT17-02 with FPS: 30\n"
     ]
    }
   ],
   "source": [
    "FRAME_FPS = {\"MOT17-13\": 25, \"MOT17-11\": 30, \"MOT17-10\": 30, \"MOT17-09\": 30,\n",
    "             \"MOT17-05\": 14, \"MOT17-04\": 30, \"MOT17-02\": 30}\n",
    "assert SAMPLE in list(FRAME_FPS.keys()), \"{} was not found.\".format(SAMPLE)\n",
    "fps = FRAME_FPS[SAMPLE]\n",
    "print(\"Sample {} with FPS: {}\".format(SAMPLE, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether or not the folder is existing, or create it if it isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_output = os.path.join(LOCAL_PATH, \"tracking_output\".format(VERSION))\n",
    "if not os.path.exists(tracking_output):\n",
    "  try:\n",
    "    os.mkdir(tracking_output)\n",
    "    print(\"Created the output path: {}\".format(tracking_output))\n",
    "  except Exception as e:\n",
    "    raise Exception(\"Can't create the folder. ({})\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we introduce how to output the tracking result on the consecutive frame to a video file. Notice the flag `plotting` must be set to `True` if you want to output the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524/524 [00:35<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time cost: 76.77822375297546\n"
     ]
    }
   ],
   "source": [
    "outputAsFramesToVideo(detection_conf=0.2,\n",
    "                      iou_threshold=0.2,\n",
    "                      min_t=fps,\n",
    "                      track_min_conf=0.5,\n",
    "                      labelFilePath=LABEL_FILE_PATH,\n",
    "                      frameFilePath=FRAME_FILE_PATH,\n",
    "                      trackingOutput=tracking_output,\n",
    "                      fps=fps,\n",
    "                      outputFileName=SAMPLE,\n",
    "                      plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can move the video to the desired path like below.\n",
    "\n",
    "```sh\n",
    "mv /tmp/MOT/tracking_output/tracking_MOT17-09.mp4 ~/Desktop/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MOT data first via the API `loadLabel`. You can also use `help` to take a look into the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS, DFPERSONS = loadLabel(src=LABEL_FILE_PATH, format_style=\"metrics_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function loadLabel in module ioutracker.dataloaders.MOTDataLoader:\n",
      "\n",
      "loadLabel(src, is_path=True, load_Pedestrian=True, load_Static_Person=True, visible_thresholde=0, format_style='onlybbox')\n",
      "    LoadLabel: Load a label file in the csv format.\n",
      "    \n",
      "    Args:\n",
      "      src: the MOT label file path (available when is_path is True)\n",
      "      is_path: True or False for whether the src is the file path or not\n",
      "      load_Pedestrian: whether to load the pedestrian data or not\n",
      "      load_Static_Person: whether to load the statuc person data or not\n",
      "      visible_thresholde: the threshold for filtering the invisible person data\n",
      "      format_style: provides different styles in the lists,\n",
      "                    \"onlybbox\" (func: formatBBoxAndVis), \"onlybbox_dict\" (func: formatBBoxAndVis),\n",
      "                    \"metrics\" (func: formatForMetrics), \"metrics_dict\" (func: formatForMetrics)\n",
      "    \n",
      "    Returns:\n",
      "      objects_in_frames: a list contains the person detection information per frames\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loadLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABELS is a dictionary whose key is the frame ID and whose value is each object detection result. The result keeps the localization and visibility in a list, more detail is `[x, y, w, h, visibility]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[912.0, 484.0, 97.0, 109.0, 1.0, 1.0],\n",
       " [1338.0, 418.0, 167.0, 379.0, 1.0, 2.0],\n",
       " [586.0, 447.0, 85.0, 263.0, 1.0, 3.0],\n",
       " [1416.0, 431.0, 184.0, 336.0, 0.51351, 8.0],\n",
       " [1056.0, 484.0, 36.0, 110.0, 0.94595, 9.0],\n",
       " [1091.0, 484.0, 31.0, 115.0, 1.0, 10.0],\n",
       " [1255.0, 447.0, 33.0, 100.0, 1.0, 14.0],\n",
       " [1016.0, 430.0, 40.0, 116.0, 0.98687, 15.0],\n",
       " [1101.0, 441.0, 38.0, 108.0, 0.6584300000000001, 17.0],\n",
       " [935.0, 436.0, 42.0, 114.0, 0.41739, 18.0],\n",
       " [442.0, 446.0, 105.0, 283.0, 1.0, 19.0],\n",
       " [636.0, 458.0, 61.0, 187.0, 0.41935, 20.0],\n",
       " [1364.0, 434.0, 51.0, 124.0, 0.0, 21.0],\n",
       " [1478.0, 434.0, 63.0, 124.0, 0.0, 22.0],\n",
       " [473.0, 460.0, 89.0, 249.0, 0.16667, 23.0],\n",
       " [835.0, 473.0, 52.0, 75.0, 1.0, 24.0],\n",
       " [796.0, 476.0, 55.0, 60.0, 0.69643, 25.0],\n",
       " [548.0, 465.0, 35.0, 93.0, 0.52778, 26.0],\n",
       " [376.0, 446.0, 41.0, 104.0, 1.0, 30.0],\n",
       " [418.0, 459.0, 40.0, 84.0, 0.58537, 31.0],\n",
       " [582.0, 456.0, 35.0, 133.0, 0.11110999999999999, 36.0],\n",
       " [972.0, 456.0, 32.0, 77.0, 0.29370999999999997, 39.0],\n",
       " [693.0, 462.0, 20.0, 67.0, 0.32633, 46.0],\n",
       " [713.0, 478.0, 19.0, 57.0, 0.24138, 47.0],\n",
       " [1004.0, 454.0, 18.0, 61.0, 0.44482, 66.0],\n",
       " [578.0, 432.0, 20.0, 43.0, 0.45779, 68.0],\n",
       " [596.0, 429.0, 18.0, 42.0, 0.36353, 69.0],\n",
       " [1036.0, 453.0, 25.0, 67.0, 0.08767, 70.0],\n",
       " [663.0, 451.0, 34.0, 86.0, 0.059770000000000004, 72.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DFPERSONS is a pandas dataframe object that is processed and filtered unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>uid</th>\n",
       "      <th>bX</th>\n",
       "      <th>bY</th>\n",
       "      <th>bW</th>\n",
       "      <th>bH</th>\n",
       "      <th>conf</th>\n",
       "      <th>class</th>\n",
       "      <th>visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>912</td>\n",
       "      <td>484</td>\n",
       "      <td>97</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>912</td>\n",
       "      <td>484</td>\n",
       "      <td>97</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>912</td>\n",
       "      <td>484</td>\n",
       "      <td>97</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>912</td>\n",
       "      <td>484</td>\n",
       "      <td>97</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>912</td>\n",
       "      <td>484</td>\n",
       "      <td>97</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fid  uid   bX   bY  bW   bH  conf  class  visible\n",
       "0    1    1  912  484  97  109     0      7      1.0\n",
       "1    2    1  912  484  97  109     0      7      1.0\n",
       "2    3    1  912  484  97  109     0      7      1.0\n",
       "3    4    1  912  484  97  109     0      7      1.0\n",
       "4    5    1  912  484  97  109     0      7      1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFPERSONS.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ioutracker that implements the IOU tracker algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iouTracks = IOUTracker(detection_conf=0.2,\n",
    "                       iou_threshold=0.2,\n",
    "                       min_t=fps,\n",
    "                       track_min_conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class IOUTracker in module ioutracker.src.IOUTracker:\n",
      "\n",
      "class IOUTracker(builtins.object)\n",
      " |  IOUTracker(detection_conf=0.5, iou_threshold=0.5, min_t=1, track_min_conf=0.5)\n",
      " |  \n",
      " |  IOUTracker implements the IOU tracker algorithm details.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, detection_conf=0.5, iou_threshold=0.5, min_t=1, track_min_conf=0.5)\n",
      " |      Constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        detection_conf (sigma_l): the detection was removed when its confident score\n",
      " |                                  is lower than detection_conf\n",
      " |        iou_threshold (sigma_IOU): the min IOU threshold between a detection and\n",
      " |                                   active tracks\n",
      " |        min_t: the track is filtered out when its length is shorter than min_t\n",
      " |        track_min_conf (sigma_h): the track is filtered out when all of its detections'\n",
      " |                                  confident scores are less than the track_min_conf\n",
      " |  \n",
      " |  clear_finished_tracks(self)\n",
      " |      clear_finished_tracks cleans finished tracks.\n",
      " |  \n",
      " |  get_active_tracks(self)\n",
      " |      get_active_tracks gets the current active tracks.\n",
      " |      \n",
      " |      Args: None\n",
      " |      \n",
      " |      Returns:\n",
      " |        active_tracks: a list of active tracks that each is a Track object\n",
      " |  \n",
      " |  get_finished_tracks(self)\n",
      " |      get_finished_tracks gets the finished tracks.\n",
      " |      \n",
      " |      Args: None\n",
      " |      \n",
      " |      Returns:\n",
      " |        finished_tracks: a list of finished tracks that each is a Track object\n",
      " |  \n",
      " |  read_detections_per_frame(self, detections)\n",
      " |      read_detections_per_frame: start to parse the detections per frame.\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: a list contains multiple detections per frame, each detection\n",
      " |                    keeps [[bX, bY, bWidth, bHeight, visible], [], []]\n",
      " |      \n",
      " |      Returns: None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  detections_transform(detection)\n",
      " |      detections_transform transforms coordinates into [bX1, bY1, bX2, bY2].\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: [bX, bY, bWidth, bHeight, visible]\n",
      " |      \n",
      " |      Returns:\n",
      " |        transformed_detections: [bX1, bY1, bX2, bY2]\n",
      " |  \n",
      " |  filter_detections(detections, detection_threshold)\n",
      " |      Filter the detections whose scores are lower than the IOU threshold.\n",
      " |      \n",
      " |      Args:\n",
      " |        detections: a list of multiple detections per frame\n",
      " |        detection_threshold: the minimum confident score\n",
      " |      \n",
      " |      Returns:\n",
      " |        available_detections: a list that removes the detections whose visible\n",
      " |                              (or probability) is lower than the detection_conf\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  detection_conf\n",
      " |      detection_conf.getter\n",
      " |  \n",
      " |  iou_threshold\n",
      " |      iou_threshold.getter\n",
      " |  \n",
      " |  min_t\n",
      " |      min_t.getter\n",
      " |  \n",
      " |  track_min_conf\n",
      " |      track_min_conf.getter\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  active_tracks = []\n",
      " |  \n",
      " |  finished_tracks = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(IOUTracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `tid_count` is used to assign the unique ID to each track. \n",
    "\n",
    "In this implementation, the IOUTracker is designed to take object detection results frame by frame, not a whole video. It keeps the information of each track. You can access the active tracks via the `get_active_tracks()` method, and watch the finished tracks via the `get_finished_tracks()` method.\n",
    " \n",
    "On the other hand, you can access the attribute `tid` of each track to get the relative track ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 50 tracker Info: active 39, finished 2\n",
      "Frame 100 tracker Info: active 37, finished 7\n",
      "Frame 150 tracker Info: active 40, finished 7\n",
      "Frame 200 tracker Info: active 41, finished 7\n",
      "Frame 250 tracker Info: active 43, finished 9\n",
      "Frame 300 tracker Info: active 45, finished 11\n",
      "Frame 350 tracker Info: active 47, finished 11\n",
      "Frame 400 tracker Info: active 46, finished 13\n",
      "Frame 450 tracker Info: active 45, finished 17\n",
      "Frame 500 tracker Info: active 44, finished 17\n",
      "Frame 550 tracker Info: active 44, finished 19\n",
      "Frame 600 tracker Info: active 44, finished 21\n",
      "Frame 650 tracker Info: active 43, finished 27\n",
      "Frame 700 tracker Info: active 40, finished 32\n",
      "Frame 750 tracker Info: active 36, finished 34\n",
      "Frame 800 tracker Info: active 43, finished 34\n",
      "Frame 850 tracker Info: active 44, finished 35\n",
      "Frame 900 tracker Info: active 46, finished 35\n",
      "Frame 950 tracker Info: active 49, finished 36\n",
      "Frame 1000 tracker Info: active 48, finished 37\n"
     ]
    }
   ],
   "source": [
    "tid_count = 1\n",
    "\n",
    "for label in range(1, len(LABELS), 1):\n",
    "  # iou tracker\n",
    "  iouTracks.read_detections_per_frame(detections=LABELS[label])\n",
    "\n",
    "  active_tacks = iouTracks.get_active_tracks()\n",
    "  finished_tracks = iouTracks.get_finished_tracks()\n",
    "\n",
    "  if label % 50 == 0:\n",
    "    print(\"Frame {} tracker Info: active {}, finished {}\".format(label, len(active_tacks), len(finished_tracks)))\n",
    "  \n",
    "  # simple way to assign the tracker ID\n",
    "  for act_track in active_tacks:\n",
    "    if not act_track.tid:\n",
    "      # assign track id to use the color\n",
    "      act_track.tid = tid_count\n",
    "      tid_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExampleEvaluateMOTDatasets helps you evaluate on each dataset or each video. Here we use the same ground truth data as the predictions to test the functionality due to the lack of a detector.\n",
    "\n",
    "Notice that this step takes a long time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions, _ = loadLabel(src=LABEL_FILE_PATH, is_path=True, load_Pedestrian=True, load_Static_Person=True,\n",
    "    visible_thresholde=0.2, format_style=\"metrics_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599/599 [05:35<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 11950\n",
      "FP:     0\n",
      "FN:     0\n",
      "GT: 11950\n",
      "Fragment Number:    159\n",
      "SwitchID Number:    263\n",
      "Recall: 100.000%\n",
      "Precision: 100.000%\n",
      "Accuracy: 100.000%\n",
      "F1 Score: 1.000\n",
      "MOTA: 0.977992\n",
      "Total trajectories: 63\n",
      "MT Number: 63, Ratio: 100.000%\n",
      "PT Number: 0, Ratio: 0.000%\n",
      "ML Number: 0, Ratio: 0.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalMOT = ExampleEvaluateMOTDatasets(LABEL_FILE_PATH, predictions=Predictions, printOnScreen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvaluateOnMOTDatasets class helps you evaluate the multiple datastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric mota: Value -0.01489539748953983\n",
      "Metric recall: Value 1.0\n",
      "Metric precision: Value 0.5017845895444047\n",
      "Metric accuracy: Value 1.0\n",
      "Metric f1score: Value 0.6682510834614847\n",
      "Metric rateMT: Value 1.0\n",
      "Metric ratePT: Value 0.0\n",
      "Metric rateML: Value 0.0\n",
      "Metric TP: Value 23900\n",
      "Metric FP: Value 23730\n",
      "Metric FN: Value 0\n",
      "Metric GT: Value 23900\n",
      "Metric numFragments: Value 159\n",
      "Metric numSwitchID: Value 263\n",
      "Metric numMT: Value 63\n",
      "Metric numPT: Value 0\n",
      "Metric numML: Value 0\n",
      "Metric numTraj: Value 63\n"
     ]
    }
   ],
   "source": [
    "evalMOTData = EvaluateOnMOTDatasets()\n",
    "\n",
    "# it is simple to pass the whole package of results into the multiple-dataset evaluator\n",
    "evalMOTData(evalMOT)\n",
    "evalMOTRes = evalMOTData.getResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also evaluate metrics on each MOT datasets and then summarize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMOTData = EvaluateOnMOTDatasets()\n",
    "for key, _ in FRAME_FPS.items():\n",
    "  LABEL_FILE_PATH = os.path.join(LABEL_PATH, key, \"gt\", \"gt.txt\")\n",
    "  assert os.path.exists(LABEL_FILE_PATH), \"{} is not found.\".format(LABEL_FILE_PATH)\n",
    "  print(\"Sample: {}\".format(key))\n",
    "  \n",
    "  # here predictions flag is set to None, it makes to use the ground truth as the prediction\n",
    "  evalMOT = ExampleEvaluateMOTDatasets(LABEL_FILE_PATH, predictions=None, printOnScreen=True)\n",
    "  evalMOTData(evalMOT)\n",
    "  print(\"\", end=\"\\n\\n\")\n",
    "evalMOTRes = evalMOTData.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
